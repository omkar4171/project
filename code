# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler

# Load the dataset (replace with your dataset path)
data = pd.read_csv('zillow_data.csv')

# Display first few rows of the dataset
print(data.head())

# Check for missing values
print("Missing Values:\n", data.isnull().sum())

# Handle missing values (fill with median values for simplicity)
data.fillna(data.median(), inplace=True)

# Drop any irrelevant columns (if any)
# Example: drop id or date columns if present
data.drop(columns=['id', 'date'], inplace=True)

# Display the dataset after cleaning
print("Data after cleaning:\n", data.head())

# 4. Data Visualization

# Box plot to detect outliers in Zestimate
plt.figure(figsize=(10,6))
sns.boxplot(x=data['Zestimate'])
plt.title('Boxplot of Zestimate')
plt.show()

# Histogram to check the distribution of Zestimate
plt.figure(figsize=(10,6))
sns.histplot(data['Zestimate'], kde=True)
plt.title('Histogram of Zestimate')
plt.show()

# Scatter plot to check correlation between sqft_living and Zestimate
plt.figure(figsize=(10,6))
sns.scatterplot(x=data['sqft_living'], y=data['Zestimate'])
plt.title('Zestimate vs. Living Area (sqft_living)')
plt.xlabel('Square Footage of Living Area')
plt.ylabel('Zestimate')
plt.show()

# 5. Pearson Correlation Matrix
corr_matrix = data.corr()

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

# 6. Identify Dependent and Independent Features

# Dependent variable (target): Zestimate
# Independent variables (features): Everything except Zestimate
X = data.drop('Zestimate', axis=1)
y = data['Zestimate']

# 7. Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 8. Standardize the features (Optional but recommended for some models)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 9. Train a Linear Regression Model
model = LinearRegression()
model.fit(X_train_scaled, y_train)

# 10. Make Predictions
y_pred = model.predict(X_test_scaled)

# 11. Evaluate the Model

# Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)
print(f'Mean Absolute Error: {mae}')

# Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

# Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)
print(f'Root Mean Squared Error: {rmse}')

# 12. Visualizing Actual vs Predicted Zestimate
plt.figure(figsize=(10,6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)
plt.title('Actual vs Predicted Zestimate')
plt.xlabel('Actual Zestimate')
plt.ylabel('Predicted Zestimate')
plt.show()

